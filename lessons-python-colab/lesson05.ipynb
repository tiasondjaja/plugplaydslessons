{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiasondjaja/plugplaydslessons/blob/master/lessons-python-colab/lesson05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP7akeRtEFDT"
      },
      "source": [
        "# Lesson 5: Classification\n",
        "\n",
        "Key Ideas:\n",
        "1. Finding patterns and making predictions about categorical variables\n",
        "    + Overview of the iterative modeling process\n",
        "    + Splitting the dataset into a training set and a validation/testing set\n",
        "    + Finding patterns in the data, using the training set\n",
        "2. Creating simple decision tree classifiers based on patterns observed in data\n",
        "3. Assessing, comparing, and improving models\n",
        "    + Assessing the performance of the model on the training dataset\n",
        "    + Assessing the performance of the model on the test dataset\n",
        "    + Metrics for model assessment\n",
        "    + k-Nearest Neighbor (kNN) Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez33yVgYEFDY"
      },
      "source": [
        "## 1. Finding patterns and making predictions about categorical variables\n",
        "\n",
        "### A quick recap of the mathematical modeling process\n",
        "\n",
        "Recall the math modeling process:\n",
        "+ Step 1: Find patterns in data\n",
        "+ Step 2: Build a model that fits the data relatively well  (e.g., fit a line through the plotted data points)\n",
        "+ Step 3: Assess the model\n",
        "+ Step 4: Repeat, until we have a model that represents the real world process sufficiently well\n",
        "+ Step 5: Use the model to make predictions/decisions\n",
        "\n",
        "In Lesson 3, (1) we found a pattern in the `geyser` data by visualizing the data points in a scatterplot.  (2) From the visualization, and by computing the correlation coefficient between the variables `duration` and `waiting`, we determine that a line is a reasonable type of model.  We then find a line of best fit (one that minimizes MSE).  Assuming that this model is reasonable, we can use the model to predict when the next eruption will take place, given the duration of an eruption that just took place.\n",
        "\n",
        "In the above example, the quantity that we want to predict is `waiting`, the number of minutes until the next eruption, which is a numerical variable. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yatHWUNEFDZ"
      },
      "source": [
        "### Predicting a categorical variable\n",
        "\n",
        "Next, we will see an example of models for predicting a categorical variable.  This type of task is called a **classification** task.  Here are some examples of classification tasks:\n",
        "+ Classifying an email as spam or not spam\n",
        "+ Given an image/photograph of an animal, determine the animal's species\n",
        "+ Given an image of a handwritten letter, determine what letter it is\n",
        "+ Given a song, determine its genre\n",
        "+ Given an activity on a website, determine if it is human or a bot\n",
        "+ etc.\n",
        "\n",
        "A binary classification task is one that involves only two possible categories (for example, human vs. bot, or spam vs. not spam).  To keep things simpler, we will focus our attention only on binary classification tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L94OqR4WEFDZ"
      },
      "source": [
        "***Example***\n",
        "\n",
        "The dataset below consists of information on 699 tumor samples.  The `id` column contains an identifier for each observed tumor.  The `class` column takes on two values: 2 (indicating that the tumor is benign) and 4 (indicating that the tumor is malignant).  In addition to the `id` and `class` columns, there are nine variables that describe various aspects of each sample.  These variables are discrete numerical variables, and could be thought of as either numerical or categorical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSWTjDqpEFDa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jF94vpYjEFDb",
        "outputId": "db44e979-8fc4-47a9-eabb-b33d351c5c53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>clump_thickness</th>\n",
              "      <th>uniformity_cellsize</th>\n",
              "      <th>uniformity_cellshape</th>\n",
              "      <th>marginal_adhesion</th>\n",
              "      <th>epithelial_cellsize</th>\n",
              "      <th>bare_nuclei</th>\n",
              "      <th>bland_chromatin</th>\n",
              "      <th>normal_nucleoli</th>\n",
              "      <th>mitoses</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000025</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002945</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015425</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1016277</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1017023</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>776715</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>841769</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>888820</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>897471</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>897471</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>699 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  clump_thickness  uniformity_cellsize  uniformity_cellshape  \\\n",
              "0    1000025                5                    1                     1   \n",
              "1    1002945                5                    4                     4   \n",
              "2    1015425                3                    1                     1   \n",
              "3    1016277                6                    8                     8   \n",
              "4    1017023                4                    1                     1   \n",
              "..       ...              ...                  ...                   ...   \n",
              "694   776715                3                    1                     1   \n",
              "695   841769                2                    1                     1   \n",
              "696   888820                5                   10                    10   \n",
              "697   897471                4                    8                     6   \n",
              "698   897471                4                    8                     8   \n",
              "\n",
              "     marginal_adhesion  epithelial_cellsize bare_nuclei  bland_chromatin  \\\n",
              "0                    1                    2           1                3   \n",
              "1                    5                    7          10                3   \n",
              "2                    1                    2           2                3   \n",
              "3                    1                    3           4                3   \n",
              "4                    3                    2           1                3   \n",
              "..                 ...                  ...         ...              ...   \n",
              "694                  1                    3           2                1   \n",
              "695                  1                    2           1                1   \n",
              "696                  3                    7           3                8   \n",
              "697                  4                    3           4               10   \n",
              "698                  5                    4           5               10   \n",
              "\n",
              "     normal_nucleoli  mitoses  class  \n",
              "0                  1        1      2  \n",
              "1                  2        1      2  \n",
              "2                  1        1      2  \n",
              "3                  7        1      2  \n",
              "4                  1        1      2  \n",
              "..               ...      ...    ...  \n",
              "694                1        1      2  \n",
              "695                1        1      2  \n",
              "696               10        2      4  \n",
              "697                6        1      4  \n",
              "698                4        1      4  \n",
              "\n",
              "[699 rows x 11 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cancerdata = pd.read_csv('../../datasets/cancerdata.csv')\n",
        "cancerdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7AAQTwmEFDc"
      },
      "source": [
        "Using the above dataset, our goal is to create a model that allows us to predict whether a tumor sample is benign or malignant (that is, whether `class` is 2 or 4), based the values of the nine predictor variables (`clump_thickness`, `uniformity_cellsize`, etc.).\n",
        "\n",
        "Such a model will have to capture a pattern that relates the values of the nine predictor variable to the value of the `class`.  To make sure that we create a model that could be generalized to other tumor data as well (that are not part of this dataset), we need to make sure that the model that we create does not 'overfit' to this particular dataset.\n",
        "\n",
        "For this reason, before we start digging into this dataset to try to find any pattern, we need to first split the dataset into training and test sets.  Each set will contains the same number of columns, but we will randomly assign the 699 rows into the training and the test sets. \n",
        "+ We will use the **training set** to find patterns in the data, to build, and to tune our model.\n",
        "+ We will use the **test set** to assess how well our model generalize to data that it has never \"seen\" before (i.e., to data that were not used to inform how the model was built).\n",
        "\n",
        "\n",
        "### Splitting the dataset into training and test sets\n",
        "\n",
        "There is no one hard rule for how we must split our dataset into training and test sets.  For example, taking 70% of all observations for the training data and the remaining 30% for the test data is acceptable for this example.\n",
        "\n",
        "One of the easiest ways to split a given dataset into training and test sets is to use a tool from the sklearn library.  To do this,\n",
        "+ First store the variable to be predicted into an array (let's call it `Y`), and store the predictor variables into a dataframe (let's call it `X`).\n",
        "+ Import the `train_test_split` function from `sklearn.model_selection`\n",
        "+ Use the `train_test_split` function:\n",
        "    + The first two inputs are `X` and `Y` as specified above\n",
        "    + The third input is `test_size`, which specifies the proportion of all observations that should be assigned to the test set; this can be any number between 0 and 1.\n",
        "    + The fourth input is `random_state`, which can take any nonnegative integer value.  The purpose of this argument is to control the pseudorandom shuffling that is applied to the dataset before it is split.  This makes sure that no matter how many times we run the command, the resulting training and test sets would remain the same instead of changing each time.\n",
        "```\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)\n",
        "```\n",
        "+ The outputs of the `train_test_split` function are:\n",
        "    + The first output contains the variables in `X` but only 70% of the observations; this will be the predictor variables in our training set (call it `X_train`)\n",
        "    + The second output contains the variables in `X` but only the remaining 30% of the observations; this will be the predictor variables in our test set (call it `X_test`) \n",
        "    + The third output contains just the `class` values of the observations in the training dataset (call it `y_train`)\n",
        "    + The fourth output contains just the `class` values of the observations in the test dataset (call it `y_test`) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yP7UdKonEFDd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = cancerdata.iloc[ : , 1:10 ]  # we take just the nine predictor variables; all 699 rows\n",
        "Y = cancerdata['class'] # just the class values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwQzUMUNEFDd",
        "outputId": "4b84b57b-76cf-4b8b-a3cf-66016d0fcc80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(489, 9)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check\n",
        "X_train.shape  # the training dataset has 489 observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjYZYB42EFDe",
        "outputId": "19ce8954-54c8-4711-d886-e474945dc6b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(210, 9)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check\n",
        "X_test.shape # the test dataset has 210 observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHDRnPrLEFDf"
      },
      "source": [
        "Above, we see that we have 489 observations in the training dataset (about 70% of 699) and 210 observations in the test dataset (about 30% of 699)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFXYzCCFEFDf"
      },
      "source": [
        "### Finding Patterns in Data\n",
        "\n",
        "We are now ready to investigate **the training dataset** to see patterns in the data, using data exploration tools that we learned in lessons 1 and 2.  (We put aside the test dataset until later, once we have built a model, in order to evaluate how well this model performs against data that it hasn't observed during its construction.)  \n",
        "\n",
        "For example, we can start by grouping the rows (the samples) based on whether the sample is benign or malignant (according to the 'class' column), then computing the average value of the nine variables, for each class.\n",
        "\n",
        "Running the code cell below, we see that for a lot of the variables, the averages are smaller among the class-2 rows than the averages among the class-4 rows.  So, we see the pattern that the higher the variable values are, the more likely it is that the sample is that of a malignant tumor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "iQ1TLPFjEFDf",
        "outputId": "8d5c1066-b01f-465f-b308-15be21e3f3ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>clump_thickness</th>\n",
              "      <th>uniformity_cellsize</th>\n",
              "      <th>uniformity_cellshape</th>\n",
              "      <th>marginal_adhesion</th>\n",
              "      <th>epithelial_cellsize</th>\n",
              "      <th>bland_chromatin</th>\n",
              "      <th>normal_nucleoli</th>\n",
              "      <th>mitoses</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.107591e+06</td>\n",
              "      <td>2.956332</td>\n",
              "      <td>1.325328</td>\n",
              "      <td>1.443231</td>\n",
              "      <td>1.364629</td>\n",
              "      <td>2.120087</td>\n",
              "      <td>2.100437</td>\n",
              "      <td>1.290393</td>\n",
              "      <td>1.063319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.003505e+06</td>\n",
              "      <td>7.195021</td>\n",
              "      <td>6.572614</td>\n",
              "      <td>6.560166</td>\n",
              "      <td>5.547718</td>\n",
              "      <td>5.298755</td>\n",
              "      <td>5.979253</td>\n",
              "      <td>5.863071</td>\n",
              "      <td>2.589212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  clump_thickness  uniformity_cellsize  \\\n",
              "class                                                       \n",
              "2      1.107591e+06         2.956332             1.325328   \n",
              "4      1.003505e+06         7.195021             6.572614   \n",
              "\n",
              "       uniformity_cellshape  marginal_adhesion  epithelial_cellsize  \\\n",
              "class                                                                 \n",
              "2                  1.443231           1.364629             2.120087   \n",
              "4                  6.560166           5.547718             5.298755   \n",
              "\n",
              "       bland_chromatin  normal_nucleoli   mitoses  \n",
              "class                                              \n",
              "2             2.100437         1.290393  1.063319  \n",
              "4             5.979253         5.863071  2.589212  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cancerdata.groupby('class').agg( 'mean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vecezc5EEFDf"
      },
      "source": [
        "We could also create data visualizations.  We cannot create a scatterplot to visualize the relationships among all nine variables at once, but we can create a scatterplot for each pair of variables, and coloring each point based on whether the point corresponds to a benign or malignant sample.\n",
        "\n",
        "The scatterplot below tells us that samples whose `clump_thickness` value is 6 or less and whose `uniformity_cellsize` value is 4 or less seem to be mostly benign (`class` = 2).  Points outside of this region seems to correspond mostly to malignant samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFkhXjFFEFDg",
        "outputId": "74f4f31d-02de-406e-f3ae-8b5bd93d1208"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x24350298648>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 402.375x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.relplot( data = cancerdata , x = 'clump_thickness', y = 'uniformity_cellsize' , hue = 'class' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqZx1JHBEFDg"
      },
      "source": [
        "***Exercise***\n",
        "\n",
        "Create a similar scatterplot to visualize other pairs of predictor variables, choosing the hue of each point based on the value of the `class` variable.  Do you observe other useful patterns?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTMX_O_VEFDg"
      },
      "outputs": [],
      "source": [
        "# ...\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBZ-cczMEFDg"
      },
      "source": [
        "## 2. Creating simple decision tree classifiers based on patterns observed in data\n",
        "\n",
        "With just the above observations, we can create a simple classification model, based only on two variables: `the uniformity_cellsize` and `clump_thickness` values.\n",
        "\n",
        "+ If `clump_thickness` is less than or equal to 6,\n",
        "    + If `uniformity_cellsize` is less than or equal to 4, then predict `class` to be 2 (benign)\n",
        "    + Otherwise (that is, `clump_thickness <= 6` but `uniformity_cellsize > 4`), then predict `class` to be 4 (malignant)\n",
        "+ Otherwise (if `clump_thickness is > 6`, regardless of what `unifromity_cellsize` is), then predict `class` to be 4 (malignant)\n",
        "\n",
        "We can implement this model as a nested if-else statement:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZy4v6k1EFDh",
        "outputId": "a8d8d44b-05a6-4eab-e9d2-9e884b8e5b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "clump_thickness = 7      # experiment and change this value\n",
        "uniformity_cellsize = 2  # experiment and change this value\n",
        "\n",
        "\n",
        "if clump_thickness <= 6 :\n",
        "    if uniformity_cellsize <= 4:\n",
        "        predicted_class = 2\n",
        "    else:\n",
        "        predicted_class = 4\n",
        "else:\n",
        "    predicted_class = 4\n",
        "\n",
        "print(predicted_class)  # display the predited class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xtjZc2xEFDh"
      },
      "source": [
        "We can further define a function to make the above code more reusable.  Let's call this function `predict_cancer_class()`\n",
        "+ whose first and second inputs are `clump_thickness` and `uniformity_cellsize` values, respectively.  \n",
        "+ The action done by this function is the sequence of decision implemented by the above nested if-else statement.  \n",
        "+ The output of the function is the predicted class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgKnDIhbEFDh"
      },
      "outputs": [],
      "source": [
        "# define the function / the model\n",
        "def predict_cancer_class( clump_thickness, predicted_class ):\n",
        "    if clump_thickness <= 6 :\n",
        "        if uniformity_cellsize <= 4:\n",
        "            predicted_class = 2\n",
        "        else:\n",
        "            predicted_class = 4\n",
        "    else:\n",
        "        predicted_class = 4\n",
        "        \n",
        "    return( predicted_class )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFbbOerfEFDi",
        "outputId": "aeac35da-08fc-46a0-b129-20de8a5c6b4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check that the function works\n",
        "\n",
        "sample_clump_thickness = 7      # experiment and change this value\n",
        "sample_uniformity_cellsize = 2  # experiment and change this value\n",
        "\n",
        "predict_cancer_class( sample_clump_thickness ,  sample_uniformity_cellsize )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oezxECUEFDi",
        "outputId": "366b3007-573a-4787-cae5-6797b01fb101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "# check that the function works, example 2\n",
        "\n",
        "sample_clump_thickness = 2      # experiment and change this value\n",
        "sample_uniformity_cellsize = 3  # experiment and change this value\n",
        "\n",
        "predicted_class_for_this_sample = predict_cancer_class( sample_clump_thickness ,  sample_uniformity_cellsize )\n",
        "\n",
        "print( predicted_class_for_this_sample )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xELhSqbiEFDj"
      },
      "source": [
        "### Using the model on the training dataset\n",
        "\n",
        "In the above two code cells, we experimented with using the model using arbitrary sample input values.  Next, we can try to make a prediction on each observation in the training dataset.\n",
        "\n",
        "In the code cell below, we preview the first few rows of the training dataset.  The `clump_thickness` and `uniformity_cellsize` values of the first observation are 3 and 4, respectively.  Our model predicts that the value of `class` is 2 for this observation (benign).\n",
        "\n",
        "We can check if this prediction is correct by viewing the first element of `y_train`, as we did below.  The actual value turns out to be 4, which means that our prediction for this observation was incorrect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oOmsQGXEFDj",
        "outputId": "8d74141c-932a-47a7-a7e4-244887cb888a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clump_thickness</th>\n",
              "      <th>uniformity_cellsize</th>\n",
              "      <th>uniformity_cellshape</th>\n",
              "      <th>marginal_adhesion</th>\n",
              "      <th>epithelial_cellsize</th>\n",
              "      <th>bare_nuclei</th>\n",
              "      <th>bland_chromatin</th>\n",
              "      <th>normal_nucleoli</th>\n",
              "      <th>mitoses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     clump_thickness  uniformity_cellsize  uniformity_cellshape  \\\n",
              "146                3                    4                     5   \n",
              "347                1                    1                     1   \n",
              "286               10                   10                    10   \n",
              "165                4                    1                     1   \n",
              "493                5                   10                    10   \n",
              "\n",
              "     marginal_adhesion  epithelial_cellsize bare_nuclei  bland_chromatin  \\\n",
              "146                  2                    6           8                4   \n",
              "347                  1                    1           1                1   \n",
              "286                 10                   10          10                4   \n",
              "165                  1                    2           2                3   \n",
              "493                 10                    6          10                6   \n",
              "\n",
              "     normal_nucleoli  mitoses  \n",
              "146                1        1  \n",
              "347                3        1  \n",
              "286               10       10  \n",
              "165                2        1  \n",
              "493                5        2  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display( X_train.head() )\n",
        "\n",
        "# predict class of the first observation (row index 146)\n",
        "predict_cancer_class(3, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9M6GWTYEFDj",
        "outputId": "a13ca19a-a3b2-4b85-e14a-1b29952a59bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "146    4\n",
              "347    2\n",
              "286    4\n",
              "165    2\n",
              "493    4\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# the actual class value of the first observation:\n",
        "y_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHQ3H31JEFDk"
      },
      "source": [
        "In order to get a good sense of how well our model performs, it is not enough to test it on just one observation.  Let's test it on the remaining 488 observations in the training dataset.  \n",
        "\n",
        "We could of course do this by hand, by manually reading and typing the values of `clump_thickness` and `uniformity_cellsize` one by one for each of these 488 observations, but this repetitive task would be tedious and time-consuming.  Instead, we will use a for loop to automate the process.\n",
        "\n",
        "We want our for loop to look up the `clump_thickness` and `uniformity_cellsize` values for each row in `X_train`, then enter them as inputs to our `predict_cancer_class` function.  Therefore, the for loop will go through each item in the list of row indices in `X_train`, which we can obtain using `X_train.index`:\n",
        "\n",
        "```\n",
        "for index in X_train.index :\n",
        "    predict_cancer_class( X_train['clump_thickness'][index] , X_train['uniformity_cellsize'][index] )\n",
        "```\n",
        "The above code is a good start, but we are not done.  Note that the predictions are currently not being stored anywhere!  Therefore, before we start the loop, we will first setup an \"empty\" array that contains just enough space to store the predicted values; let's call this array `y_train_predicted`.\n",
        "```\n",
        "y_train_predicted = np.zeros( y_train.shape ).astype(int)\n",
        "y_train_predicted = pd.Series(y_train_predicted)\n",
        "y_train_predicted.index = y_train.index\n",
        "```\n",
        "In the above code, \n",
        "+ We use the function `np.zeros` to create an array called `y_train_predicted` whose values are all zeros.  The array will have the same number of elements as `y_train`.  (We add `.astype(int)` because the value that we want to predict is 2 or 4, integers, so we set this placeholder to hold integer values as well.) This first line is the most important step; the next two lines are not conceptually important but makes things a bit easier technically.\n",
        "+ Since `y_train` is not just an array but in fact something called a \"pandas Series\", we convert `y_train_predicted` into a pandas Series as well, using the `pd.Series` function.\n",
        "+ Finally, we want to make the row indices of `y_train_predicted` consistent with the row indices of `X_train` and `y_train`.  We do this using: `y_train_predicted.index = y_train.index`\n",
        "\n",
        "\n",
        "Finally, we can store the predictions of our model in the `y_train_predicted` by modifying the loop to be as follows.\n",
        "```\n",
        "for index in X_train.index :\n",
        "    y_train_predicted[index] = predict_cancer_class( X_train['clump_thickness'][index] , X_train['uniformity_cellsize'][index] )\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHbryhelEFDk"
      },
      "outputs": [],
      "source": [
        "y_train_predicted = np.zeros( y_train.shape ).astype(int)\n",
        "y_train_predicted = pd.Series(y_train_predicted)\n",
        "y_train_predicted.index = y_train.index\n",
        "\n",
        "# make a prediction for the value of class, for each row in the training dataset.\n",
        "for index in X_train.index :\n",
        "    y_train_predicted[index] = predict_cancer_class( X_train['clump_thickness'][index] , X_train['uniformity_cellsize'][index] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9Uebwu5EFDk",
        "outputId": "59371298-fe8d-499f-8379-c3cde6357fc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "146    2\n",
              "347    2\n",
              "286    4\n",
              "165    2\n",
              "493    2\n",
              "      ..\n",
              "144    2\n",
              "645    2\n",
              "72     2\n",
              "235    2\n",
              "37     2\n",
              "Length: 489, dtype: int32"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check\n",
        "y_train_predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHCN4OvVEFDk"
      },
      "source": [
        "## 3. Assessing, comparing, and improving models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKbvx7woEFDk"
      },
      "source": [
        "### 3.1. Assessing the performance of the model on the training dataset\n",
        "\n",
        "#### Counting the number of correct predictions\n",
        "Above, we have stored our predictions in `y_train_predicted`.  We can compare this value to the actual class values in `y_train`.  One way to assess the quality of our model is simply to count how many of the predictions we get right.\n",
        "\n",
        "We can use \n",
        "```\n",
        "y_train_predicted == y_train\n",
        "```\n",
        "(with two equal signs!) to check whether the elements of `y_train_predicted` is equal to the corresponding elements of `y_train`.  Recall that `y_train_predicted` and `y_train` each has 489 values; the result of the above line will be 489 boolean values (`True` or `False`), depending on whether or not the corresponding predicted value is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "sdiNcJx_EFDk",
        "outputId": "d857ae1e-4df2-4fba-8071-9ddad00425a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "146    False\n",
              "347     True\n",
              "286     True\n",
              "165     True\n",
              "493    False\n",
              "       ...  \n",
              "144     True\n",
              "645     True\n",
              "72      True\n",
              "235     True\n",
              "37      True\n",
              "Length: 489, dtype: bool"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_predicted == y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4mZzXw5EFDk"
      },
      "source": [
        "Python treats `False` as the value 0 and `True` as 1, therefore we can use `sum( y_train_predicted == y_train )` to count the number of correct predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RfZOmlAEFDl",
        "outputId": "80e41fbb-aff4-45aa-fec9-7b6c2be99e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "419\n"
          ]
        }
      ],
      "source": [
        "num_correct = sum( y_train_predicted == y_train )\n",
        "print(num_correct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0yiGnohEFDl"
      },
      "source": [
        "#### Computing accuracy\n",
        "\n",
        "A better measure of the model performance would be to compute the model's **accuracy**, which is the ratio of the number of correct predictions and the number of all predictions:\n",
        "\n",
        "$$ \\text{ accuracy } = \\frac{\\text{ number of correct predictions} }{ \\text{number of all predictions} }$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSMOaYv2EFDl",
        "outputId": "fcfdb9a4-4dbe-429a-a24f-12c4c7c2db5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "419\n",
            "489\n",
            "0.8568507157464212\n"
          ]
        }
      ],
      "source": [
        "num_all = len( y_train_predicted )  # this should be the same as len( y_train )\n",
        "accuracy = num_correct / num_all    # ratio of num correct to num of all predictions\n",
        "print(num_correct)\n",
        "print(num_all)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5lXzNdREFDl"
      },
      "source": [
        "That is, the accuracy of our model on the training dataset is about 85.7%.  This is not too bad for a simple first model!\n",
        "\n",
        "Here, we use **accuracy** as the 'score' or the 'metric' we use to assess our model; the closer it is to 100\\%, the better.  Accuracy is not the only assessment metric that we could use; we will see a few other other metrics in Section 3.3.\n",
        "\n",
        "\n",
        "### 3.2. Assessing the performance of the model on the test dataset\n",
        "\n",
        "We have seen that our model performs relatively well on the training dataset, making about 85.7% correct predictions among the data that it has observed.  Next, we want to see how well the model generalizes: how well it performs on data that it has not observed during the model-building stage.  This step is very important, becase models that only perform well on data that it has seen isn't useful.\n",
        "\n",
        "Recall that we did the following to make predictions on the training dataset:\n",
        "```\n",
        "y_train_predicted = np.zeros( y_train.shape ).astype(int)\n",
        "y_train_predicted = pd.Series(y_train_predicted)\n",
        "y_train_predicted.index = y_train.index\n",
        "\n",
        "# make a prediction for the value of class, for each row in the training dataset.\n",
        "for index in X_train.index :\n",
        "    y_train_predicted[index] = predict_cancer_class( X_train['clump_thickness'][index] , X_train['uniformity_cellsize'][index] )\n",
        "```\n",
        "\n",
        "We can repeat this procedure, but applying the `predict_cancer_class()` function on `X_test` instead of `X_train`; we will also adjust the names of the various lists accordingly, and compute the accuracy of the prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R34MKGtzEFDl"
      },
      "outputs": [],
      "source": [
        "y_test_predicted = np.zeros( y_test.shape ).astype(int)   # Setup a 'blank' array to hold the model output on the test data\n",
        "y_test_predicted = pd.Series(y_test_predicted)\n",
        "y_test_predicted.index = y_test.index\n",
        "\n",
        "# make a prediction for the value of class, for each row in the test dataset.\n",
        "for index in X_test.index :\n",
        "    y_test_predicted[index] = predict_cancer_class( X_test['clump_thickness'][index] , X_test['uniformity_cellsize'][index] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsoEa7unEFDl",
        "outputId": "488e627b-f7e9-47dc-ae23-7651d5301dac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "584    2\n",
              "417    2\n",
              "606    2\n",
              "349    2\n",
              "134    2\n",
              "      ..\n",
              "440    4\n",
              "299    4\n",
              "577    2\n",
              "103    4\n",
              "659    2\n",
              "Length: 210, dtype: int32"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# preview the result\n",
        "y_test_predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E9dVKk0EFDl",
        "outputId": "b58aba4c-6698-49e7-9535-818c5f9b59e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "181\n",
            "210\n",
            "0.861904761904762\n"
          ]
        }
      ],
      "source": [
        "# compute the accuracy of this prediction\n",
        "\n",
        "num_correct_test = sum( y_test_predicted == y_test )  # count how many predictions are correct\n",
        "print( num_correct_test )\n",
        "\n",
        "num_all_test = len( y_test )  # count the total number of predictions\n",
        "print( num_all_test )\n",
        "\n",
        "accuracy_test = num_correct_test/ num_all_test   # compute accuracy\n",
        "print(accuracy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2fg0dWcEFDm"
      },
      "source": [
        "The accuracy of our model on the test dataset is about 86.2%, which is comparable (and slightly better) than the accuracy of the model on the training dataset.  This is great!\n",
        "\n",
        "\n",
        "In general, we might expect the model to perform slightly worse on the test dataset.  If the model performs a lot worse on the test dataset, then the model is \"overfitted\" to the training dataset: it captures patterns in the training dataset very well but fails to capture more general patterns that might arise in the test dataset.\n",
        "\n",
        "Of course, we might want to tweak our model (or consider a different model) to achieve higher accuracies on both the training and test datasets.  This will be your task in this lesson's final exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YgnLfa2EFDm"
      },
      "source": [
        "### 3.3. Metrics for model assessment\n",
        "\n",
        "Above, we assessed a model's performance by computing its accuracy.  In some cases, however, accuracy alone does not sufficiently reflect the quality of a model.  Consider the following example.\n",
        "\n",
        "***Motivating Example***\n",
        "\n",
        "Consider a classification task for detecting a rare disease: 0 if the disease is not present (i.e., a negative case for the disease) and 1 otherwise (i.e., a positive case).  Suppose that our test dataset contains a total of 10000 observations, with only 5 positive positive cases and 9995 negative cases.\n",
        "\n",
        "Let us construct a very simple prediction model that always predicts 0 (that the disease is not present).  Clearly, this model is useless!  However, the accuracy of this model on the test dataset is very high:  Since it always predicts 0 and the test dataset contains 9995 negative cases, then the accuracy is $\\frac{9995}{10000} = 0.9995$ or 99.95\\%.\n",
        "\n",
        "In this above example, the model correctly identifies 100\\% of the 99995 negative cases but 0\\% of the 5 positive cases!  Since the point is to help identify occurences of this rare disease, then for this case study, a good model should do a better job identifying the positive cases.\n",
        "\n",
        "*****\n",
        "\n",
        "This example motivates the need for additional metrics that helps capture how well a classification model identify each possible outcome.  \n",
        "\n",
        "#### First, some terminology\n",
        "\n",
        "Given a binary classification task, choose one outcome as the \"positive\" outcome and the other as the \"negative\" outcome.  For example, the presence of a rare disease or a malignant tumor might the the \"positive\" outcome (a positive case, even though its undesireable).\n",
        "\n",
        "We define the following terms:\n",
        "+ **True Positive**: The model predicts the positive case, and this prediction is correct.\n",
        "+ **False Positive**: The model predicts the positive case, and this prediction is incorrect (it is actually a negative case).\n",
        "+ **True Negative**: The model predicts the negative case, and this prediction is correct.\n",
        "+ **False Negative**: The model predicts the negative case, and this prediction is incorrect (it is actually a positive case).\n",
        "\n",
        "Instead of only counting the number of correct predictions made by a model as we did previously, we can also count the number of True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN).\n",
        "\n",
        "We can summarize the above information in a **confusion matrix**: a table with 2 rows and 2 columns where \n",
        "+ The rows correspond to the actual values (positive or negative)\n",
        "+ The columns correspond to the predicted values (positive or negative)\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "    <td>\n",
        "    </td>\n",
        "    <td>\n",
        "    </td>\n",
        "    <th colspan = 2 style=\"text-align: center\">Predicted\n",
        "    </th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>\n",
        "    </td>\n",
        "    <td>\n",
        "    </td>\n",
        "    <th>Positive\n",
        "    </th>\n",
        "    <th>Negative\n",
        "    </th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <th rowspan = 2> Actual\n",
        "    </th>\n",
        "    <th>Positive\n",
        "    </th>\n",
        "    <td style=\"text-align: left\">TP\n",
        "    </td>\n",
        "    <td style=\"text-align: left\">FN\n",
        "    </td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <th>Negative\n",
        "    </th>\n",
        "    <td style=\"text-align: left\">FP\n",
        "    </td>\n",
        "    <td style=\"text-align: left\">TN\n",
        "    </td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "In terms of our new vocabulary,\n",
        "$$ \\text{accuracy} = \\frac{\\text{ number of correct predictions} }{ \\text{number of all predictions} } = \\frac{\\text{TP}+\\text{TN}}{\\text{TP}+\\text{TN}+\\text{FP}+\\text{FN}}.$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TVZFcrzEFDm"
      },
      "source": [
        "***Motivating Example (continued)***\n",
        "\n",
        "Let's consider again the above example: we have a total of 10000 observations, with only 5 positive positive cases and 9995 negative cases, along with a model that makes 10000 negative predictions and 0 positive ones.  The model makes 9995 correct negative predictions and 5 incorrect negative predictions.  Therefore,\n",
        "+ The number of True Positives (TP) = 0\n",
        "+ The number of False Positives (FP) = 0\n",
        "+ The number of True Negatives (TN) = 9995\n",
        "+ The number of False Negatives (FN) = 5\n",
        "\n",
        "(These four numbers should sum up to 10000, the total number of observations in the dataset.)\n",
        "\n",
        "The corresponding confusion matrix:\n",
        "<table>\n",
        "<tr>\n",
        "    <td>\n",
        "    </td>\n",
        "    <td>\n",
        "    </td>\n",
        "    <th colspan = 2 style=\"text-align: center\">Predicted\n",
        "    </th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>\n",
        "    </td>\n",
        "    <td>\n",
        "    </td>\n",
        "    <th>Positive\n",
        "    </th>\n",
        "    <th>Negative\n",
        "    </th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <th rowspan = 2> Actual\n",
        "    </th>\n",
        "    <th>Positive\n",
        "    </th>\n",
        "    <td style=\"text-align: left\">TP = 0\n",
        "    </td>\n",
        "    <td style=\"text-align: left\">FN = 5\n",
        "    </td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <th>Negative\n",
        "    </th>\n",
        "    <td style=\"text-align: left\">FP = 0\n",
        "    </td>\n",
        "    <td style=\"text-align: left\">TN = 9995\n",
        "    </td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "The accuracy of this prediction is\n",
        "$$ \\text{accuracy} = \\frac{\\text{TP}+\\text{TN}}{\\text{TP}+\\text{TN}+\\text{FP}+\\text{FN}} = \\frac{0 + 9995}{0+ 9995 + 0 + 5} = \\frac{9995}{10000} = 0.9995$$\n",
        "or 99.95\\%.\n",
        "\n",
        "\n",
        "Earlier, we noted that if we only look at the cases that are actually negative, then the model correctly predicts 100% of them.  Here, \"100%\" is computed as follows\n",
        "$$ \\frac{ \\text{number of all negative cases that are correctly predicted as negative} }{ \\text{number of all cases that are actually negative} }, $$\n",
        "in other words:\n",
        "$$ \\frac{ \\text{TN} }{ \\text{TN + FP} } = \\frac{9995}{9995 + 0}. $$\n",
        "  <br>\n",
        "\n",
        "We also noted that if we only look at the cases that are actually positive, then the model correctly predictes 0% of them!  Here, \"0%\" is computed as follows\n",
        "$$ \\frac{ \\text{number of all positive cases that are correctly predicted as positive} }{ \\text{number of all cases that are actually positive} }, $$\n",
        "in other words:\n",
        "$$ \\frac{ \\text{TP} }{ \\text{TP + FN} } = \\frac{0}{0+5}. $$\n",
        "\n",
        "*****\n",
        "\n",
        "\n",
        "The above two metrics are often referred to as \"specificity\" and \"recall\", respectively.  There are also other metrics that we can compute in terms of TP, FP, TN, and FN.  Below are some of them; you can find others [here](https://en.wikipedia.org/wiki/Confusion_matrix#Table_of_confusion).\n",
        "\n",
        "**Specificity** <br>(also known as \"selectivity\" or \"True Negative Rate\")\n",
        "$$ \\frac{ \\text{TN} }{ \\text{TN + FP} }, $$\n",
        "the ratio of correct predictions among all observations that are actually negative.\n",
        "\n",
        "**Recall** <br>(also known as \"sensitivity\", \"hit rate\", or \"True Positive Rate\")\n",
        "$$ \\frac{ \\text{TP} }{ \\text{TP + FN} } ,$$\n",
        "the ratio of correct predictions among all observations that are actually positive.\n",
        "\n",
        "**Precision** <br>\n",
        "$$ \\frac{ \\text{TP} }{ \\text{TP + FP} }, $$\n",
        "the ratio of correct predictions among all observations that are predicted to be positive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRzbini1EFDn"
      },
      "source": [
        "***Example***\n",
        "\n",
        "Let us now return to our main example of classifying tumors as benign or malignant.  We have previously computed the accuracy of our model on the training dataset.  Let us now compute the specificity, recall, and precision of our model on the training dataset.  To do this, we first need to count the number of true positives, true negatives, false positives, and false negatives in our predictions.\n",
        "\n",
        "\n",
        "To do this, we will first setup a data frame (let's call it `training_results_df`) that has 6 columns: 'y_train', 'y_train_predicted', 'TP', 'TN', 'FP', and 'FN':"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "yK7ncoiyEFDn",
        "outputId": "c2a2bcf7-c36e-42b6-8866-f280b0d5a907"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_train</th>\n",
              "      <th>y_train_predicted</th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     y_train  y_train_predicted   TP   TN   FP   FN\n",
              "146        4                  2  0.0  0.0  0.0  0.0\n",
              "347        2                  2  0.0  0.0  0.0  0.0\n",
              "286        4                  4  0.0  0.0  0.0  0.0"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_results_df = pd.DataFrame( {'y_train': y_train, # this column contains the actual y values in the training data\n",
        "                                     'y_train_predicted': y_train_predicted, # this column contains the predicted y values\n",
        "                                     'TP': np.zeros( len(y_train) ), # fill this column with zeros for now \n",
        "                                     'TN': np.zeros( len(y_train) ), # fill this column with zeros for now\n",
        "                                     'FP': np.zeros( len(y_train) ), # fill this column with zeros for now\n",
        "                                     'FN': np.zeros( len(y_train) ) # fill this column with zeros for now \n",
        "                                    })\n",
        "\n",
        "# preview the first few rows:\n",
        "training_results_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L527fbpiEFDn"
      },
      "source": [
        "Then, we will go through each row of this data frame to check whether the row corresponds to a true positive, true negative, false positive, or false negative.  We will then fill in a 1 to replace the zero in the appropriate column.\n",
        "\n",
        "\n",
        "Recall that 2 indicates that the tumor is benign and 4 indicates that the tumor is malignant.  There is some freedom on how to interpret which of the two outcome is \"positive\" and which is \"negative\", depending on context.  In this example, let us follow the convention of that a positive diagnosis is the presence of an illness; that is, **we will interpret 4/malignant as a positive case** (\"the diagnosis of malignant cancer is positive\", an undesireable outcome) and **2/benign as a negative case**.\n",
        "\n",
        "For example, the case the first row (index 146) is actually positive but is predicted to be negative.  Therefore, this is a false negative result.  We will seek to enter the number 1 in the FN column of this row, leaving the other three columns as zeros.\n",
        "\n",
        "We will use a for loop to go through each row of this data frame.  For each row, we will check which of the four cases is satisfied, using if/else statements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbXRmF-kEFDn",
        "outputId": "2c84c71f-f1e3-4b02-f280-be3876bb5e75"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_train</th>\n",
              "      <th>y_train_predicted</th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     y_train  y_train_predicted   TP   TN   FP   FN\n",
              "146        4                  2  0.0  0.0  0.0  1.0\n",
              "347        2                  2  0.0  1.0  0.0  0.0\n",
              "286        4                  4  1.0  0.0  0.0  0.0"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we will go through each row of the dataframe by looping over its row indices\n",
        "for i in training_results_df.index : \n",
        "    actual_value = training_results_df.loc[i, 'y_train']      # get value in row index i, column y_train\n",
        "    predicted_value = training_results_df.loc[i, 'y_train_predicted']  # get value in row index i, column y_train_predicted\n",
        "    \n",
        "    if actual_value == 4 and predicted_value == 4:   # actual is positive, predicted is positive --> True Positive\n",
        "        training_results_df.loc[i, 'TP'] = 1    # Set TP to 1; leave other values at 0\n",
        "    elif actual_value == 4 and predicted_value == 2: # actual is positive, predicted is negative --> False Negative\n",
        "        training_results_df.loc[i, 'FN'] = 1    # Set FN to 1; leave other values at 0\n",
        "    elif actual_value == 2 and predicted_value == 4: # actual is negative, predicted is positive --> False Positive\n",
        "        training_results_df.loc[i, 'FP'] = 1    # Set FP to 1; leave other values at 0\n",
        "    elif actual_value == 2 and predicted_value == 2: # actual is negative, predicted is negative --> True Negative\n",
        "        training_results_df.loc[i, 'TN'] = 1    # Set TN to 1; leave other values at 0\n",
        "        \n",
        "# preview the updated dataframe\n",
        "training_results_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_CY4ONnEFDn"
      },
      "source": [
        "Then, to find the total number of true positives, true negatives false positives, and false negatives, we take the sum of each of these columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AZW3ee0EFDo",
        "outputId": "397365b1-5df3-4cfe-e16f-1175e3b0a7e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "102.0\n",
            "317.0\n",
            "4.0\n",
            "66.0\n",
            "489.0\n",
            "489\n"
          ]
        }
      ],
      "source": [
        "num_tp = np.sum(training_results_df['TP'])\n",
        "num_tn = np.sum(training_results_df['TN'])\n",
        "num_fp = np.sum(training_results_df['FP'])\n",
        "num_fn = np.sum(training_results_df['FN'])\n",
        "\n",
        "# display the numbers\n",
        "print( num_tp )\n",
        "print( num_tn )\n",
        "print( num_fp )\n",
        "print( num_fn )\n",
        "\n",
        "# check: the sum of the above four numbers should be equal to \n",
        "#  the number of observations ( which is also the number of rows of this dataframe)\n",
        "print( num_tp + num_tn + num_fp + num_fn )\n",
        "print( training_results_df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CMhSQZSEFDo"
      },
      "source": [
        "Finally, let us compute the accuracy, precision, and recall of the model on this training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qBriVMbEFDo",
        "outputId": "050d83df-b123-44e7-c676-8c6c3c0ff41d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:\n",
            "0.8568507157464212\n",
            "Precision:\n",
            "0.9622641509433962\n",
            "Recall:\n",
            "0.6071428571428571\n"
          ]
        }
      ],
      "source": [
        "accuracy = ( num_tp + num_tn ) / ( num_tp + num_tn + num_fp + num_fn )\n",
        "precision = ( num_tp ) / ( num_tp + num_fp )\n",
        "recall = ( num_tp  ) / ( num_tp + num_fn )\n",
        "\n",
        "print('Accuracy:')\n",
        "print(accuracy)\n",
        "print('Precision:')\n",
        "print(precision)\n",
        "print('Recall:')\n",
        "print(recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D9lGtvkEFDo"
      },
      "source": [
        "We see that our model has a relatively high precision of about 96.2\\%, which means that among all observations in the training dataset that are malignant tumors, the model correctly identify them 96.2\\% of the time.\n",
        "\n",
        "On the other hand, the model has a relatively low recall of about 60.7\\%, which means that among all observations in the training dataset that are predicted as malignant tumor, the model only gets 60.7\\% of them right.  That is, about 49.3\\% of those prediced as malignant are actually benign.\n",
        "\n",
        "These two additional pieces of information was not gleaned when we only computed the overall accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNAE0RaIEFDp"
      },
      "source": [
        "### 3.4. k-Nearest Neighbor (kNN) Classifiers\n",
        "\n",
        "In our running example above, we assessed the performance of our simple decision tree classifier, which we implemented as the function `predict_cancer_class()`.  Recall that we built this classifier based on a pattern that we observed: When we create a scatterplot that visualizes the uniformity of cell size and clump thickness variables, tumors that are benign tend to cluster at low values of uniformity of cell size and clump thickness.  We can try to improve our model by creating other decision tree classifiers based on similar observations of other variables in this dataset (as you will do in Exercise 2 below).\n",
        "\n",
        "We can also consider other types of classifiers.  In this last part of our lesson, we will discuss the k-Nearest Neighbor Classifier.  The idea behind this classifier is simple:  Given a new tumor data point that we want to predict to be either benign or malignant, we might try to look for data points in our training set (which we know to be benign or malignant) whose variable values are as near as possible to those of the new data point.  If the majority of these nearby points are malignant, then we predict the new data point to be from a malignant tumor as well; similarly, if the majority of nearby points are benign, we predict the new data point to be from a benign tumor.\n",
        "\n",
        "That is, to predict the class of a new observation (such as an observation in our test dataset):\n",
        "1. Find k points in the training dataset that are \"closest\" to the current new observation\n",
        "2. \"Majority Vote\": We predict the class of the current new observation to be the majority class among these k nearest neighbors.\n",
        "\n",
        "Note that we haven't specified what we mean by \"closest\" and how many neighbors to consider (that is, how to choose $k$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_eCr10KEFDp"
      },
      "source": [
        "#### Quantifying Closeness\n",
        "\n",
        "The default choice for quantifying \"closeness\" between data points is simply the Euclidean distance between them.\n",
        "\n",
        "***Example*** \n",
        "Consider the first three observations in our training dataset.  For simplicity, let us consider only the clump thickness and uniformity of cell size variables of each tumor data.\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <th>id\n",
        "        </th>\n",
        "        <th>clump_thickness\n",
        "        </th>\n",
        "        <th>uniformity_cellsize\n",
        "        </th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>1000025\n",
        "        </td>\n",
        "        <td>5\n",
        "        </td>\n",
        "        <td>1\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>1002945\n",
        "        </td>\n",
        "        <td>5\n",
        "        </td>\n",
        "        <td>4\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>1015425\n",
        "        </td>\n",
        "        <td>3\n",
        "        </td>\n",
        "        <td>1\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "Using the distance formula, the distance between the first and the second observations is\n",
        "$$\\sqrt{ (5-5)^2 + (1-4)^2} = \\sqrt{0 + 9} = 3$$\n",
        "and the distance between the second and the third observation is\n",
        "$$\\sqrt{ (5-3)^2 + (4-1)^2 } = \\sqrt{4 + 9} = \\sqrt{13}.$$\n",
        "That is, the first point is closer to the second point than the third point is to the second point.\n",
        "\n",
        "Note that we still have some decisions to be made: Which of the variables in the dataset should be included in computing distance?  There are nine variables in our cancer dataset, and our choice of which variables to include will change the distance between the observations.    \n",
        "\n",
        "***Example (continued)*** \n",
        "Consider the same three observations in our training dataset, but in addition to clump thickness and uniformity of cell size, let us also include the `bare_nuclei` variable in computing the distance between the data points.\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <th>id\n",
        "        </th>\n",
        "        <th>clump_thickness\n",
        "        </th>\n",
        "        <th>uniformity_cellsize\n",
        "        </th>\n",
        "        <th>bare_nuclei\n",
        "        </th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>1000025\n",
        "        </td>\n",
        "        <td>5\n",
        "        </td>\n",
        "        <td>1\n",
        "        </td>\n",
        "        <td>1\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>1002945\n",
        "        </td>\n",
        "        <td>5\n",
        "        </td>\n",
        "        <td>4\n",
        "        </td>\n",
        "        <td>10\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>1015425\n",
        "        </td>\n",
        "        <td>3\n",
        "        </td>\n",
        "        <td>1\n",
        "        </td>\n",
        "        <td>2\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "Using the distance formula (for three variables), the distance between the first and the second observations is\n",
        "$$\\sqrt{ (5-5)^2 + (1-4)^2 + (1-10)^2} = \\sqrt{0 + 9 + 81} = \\sqrt{90}$$\n",
        "and the distance between the second and the third observation is\n",
        "$$\\sqrt{ (5-3)^2 + (4-1)^2 + (10-2)^2} = \\sqrt{4 + 9 + 64} = \\sqrt{77}.$$\n",
        "The first point is farther from the second point than the third point is from the second point.\n",
        "\n",
        "The process for choosing which subset of variables to consider during the modeling process is often referred to as \"variable selection\".  Each set of variables essentially corresponds to one model choice; we can assess whether this selection is a good one the same way we might assess a model: we can compute one or more metrics to evaluate how well the model performs on both the training and test dataset.  Ideally, a good model (and a good selection of variables) leads to good scores on both the training and test dataset.  There are also other factors to consider during variable selection that are beyond the scope of this lesson.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ9c1yCFEFDp"
      },
      "source": [
        "#### Choice of k\n",
        "\n",
        "In general, we can consider any number of nearest neighbors; that is $k$ could be any positive intenger.  However, if we want to make sure that no tie-breaking is needed when we determine which class forms the majority mong the nearest neighbor, $k$ can be chosen to be an odd number.\n",
        "\n",
        "As with variable selection, each choice of $k$ essentially lead to a model.  Therefore, for each possible value of $k$ that we are considering, we can compute one or more metrics to evaluate how well the model performs on both the training and test dataset, and choose the value of $k$ that leads to good scores on both the training and test dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4isSQ3jEFDp"
      },
      "source": [
        "#### Using the k-Nearest Neighbor (kNN) classifier\n",
        "\n",
        "We can construct a kNN classifier from scratch but we won't do that here.  Instead, we will use an implementation from scikit-learn, a python library.\n",
        "\n",
        "```\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier(n_neighbors=k)\n",
        "model.fit(X, y)\n",
        "\n",
        "# then, to make a prediction\n",
        "y_predicted = model.predict( X )\n",
        "```\n",
        "where\n",
        "+ `k` = a positive integer\n",
        "+ `X` = a **dataframe** with the column of the independent variable\n",
        "+ `y` = a list/array containing the values of the dependent variable\n",
        "\n",
        "\n",
        "***Example***\n",
        "\n",
        "Consider the `cancerdata` dataset again, split into the training and test dataset above (`X_train`, `X_test`).  Suppose that we would like to make a prediction using only the clump thickness and uniformity of cell size columns, with $k = 5$.  We first use the training dataset to fit the model:\n",
        "```\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "X = X_train[['clump_thickness', 'uniformity_cellsize']]\n",
        "y = y_train\n",
        "\n",
        "model.fit(X, y)  # fit using training data\n",
        "\n",
        "```\n",
        "Then, let us evaluate the accuracy of this model performs on the test dataset:\n",
        "\n",
        "```\n",
        "y_test_knn_predicted = model.predict( X_test[['clump_thickness', 'uniformity_cellsize']] )\n",
        "\n",
        "# use the method we have used before for computing the accuracy of our decision tree classifier:\n",
        "\n",
        "num_correct_knn_test = sum( y_test_knn_predicted == y_test )  # count how many predictions are correct\n",
        "print( num_correct_knn_test )\n",
        "\n",
        "num_all_test = len( y_test )  # count the total number of predictions\n",
        "print( num_all_test )\n",
        "\n",
        "accuracy_knn_test = num_correct_knn_test/ num_all_test   # compute accuracy\n",
        "print(accuracy_knn_test)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwwlzuR4EFDq",
        "outputId": "6832bd75-0037-45c7-fac3-ce04e5d7afd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "202\n",
            "210\n",
            "0.9619047619047619\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "X = X_train[['clump_thickness', 'uniformity_cellsize']]\n",
        "y = y_train\n",
        "model.fit(X, y)\n",
        "\n",
        "\n",
        "# predict\n",
        "y_test_knn_predicted = model.predict( X_test[['clump_thickness', 'uniformity_cellsize']] )\n",
        "\n",
        "# compute accuracy\n",
        "num_correct_knn_test = sum( y_test_knn_predicted == y_test )  # count how many predictions are correct\n",
        "print( num_correct_knn_test )\n",
        "\n",
        "num_all_test = len( y_test )  # count the total number of predictions\n",
        "print( num_all_test )\n",
        "\n",
        "accuracy_knn_test = num_correct_knn_test/ num_all_test   # compute accuracy\n",
        "print(accuracy_knn_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCL6r4jfEFDq"
      },
      "source": [
        "Note that the accuracy of this classifier on the test dataset is about 96.2\\%!\n",
        "\n",
        "***Exercise***\n",
        "\n",
        "Modify the above code cell to try other other values of $k$ and other set of variables.  How does these choices change the accuracy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf-mpZyAEFDq"
      },
      "source": [
        "***Exercise***\n",
        "\n",
        "Find the precision and recall of the above kNN classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns3Et-NWEFDq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T1JKkqWEFDq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu1Vh_bQEFDq"
      },
      "source": [
        "## Lesson 5 Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvQc-gJVEFDr"
      },
      "source": [
        "***Exercise 1***\n",
        "\n",
        "The code cell below summarizes the codes used to compute the accuracy, precision, and recall of the model on the **training** dataset.\n",
        "\n",
        "Please modify this code cell to compute the accuracy, precision, and recall of the model on the **test** dataset.  How do the accuracy, precision, and recall on the test dataset compare to these metrics on the training dataset?  What does this say about the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppp4sRZiEFDr"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Use the predict_cancer_class() function to make a prediction on the test dataset\n",
        "# TODO: modify the codes below to do this on the test dataset (currently it's for the training dataset)\n",
        "\n",
        "y_train_predicted = np.zeros( y_train.shape ).astype(int)\n",
        "y_train_predicted = pd.Series(y_train_predicted)\n",
        "y_train_predicted.index = y_train.index\n",
        "\n",
        "# make a prediction for the value of class, for each row in the training dataset.\n",
        "for index in X_train.index :\n",
        "    y_train_predicted[index] = predict_cancer_class( X_train['clump_thickness'][index] , X_train['uniformity_cellsize'][index] )\n",
        "\n",
        "    \n",
        "\n",
        "# STEP 2: Take each predictions from STEP 1 and count the number of true positives, true negatives, etc.\n",
        "# TODO: modify the codes below to do this on the test dataset (currently it's for the training dataset)\n",
        "\n",
        "# first set up a placeholder dataframe\n",
        "training_results_df = pd.DataFrame( {'y_train': y_train, # this column contains the actual y values in the training data\n",
        "                                     'y_train_predicted': y_train_predicted, # this column contains the predicted y values\n",
        "                                     'TP': np.zeros( len(y_train) ), # fill this column with zeros for now \n",
        "                                     'TN': np.zeros( len(y_train) ), # fill this column with zeros for now\n",
        "                                     'FP': np.zeros( len(y_train) ), # fill this column with zeros for now\n",
        "                                     'FN': np.zeros( len(y_train) ) # fill this column with zeros for now \n",
        "                                    })\n",
        "\n",
        "\n",
        "# we will go through each row of the dataframe by looping over its row indices\n",
        "for i in training_results_df.index : \n",
        "    actual_value = training_results_df.loc[i, 'y_train']      # get value in row index i, column y_train\n",
        "    predicted_value = training_results_df.loc[i, 'y_train_predicted']  # get value in row index i, column y_train_predicted\n",
        "    \n",
        "    if actual_value == 4 and predicted_value == 4:   # actual is positive, predicted is positive --> True Positive\n",
        "        training_results_df.loc[i, 'TP'] = 1    # Set TP to 1; leave other values at 0\n",
        "    elif actual_value == 4 and predicted_value == 2: # actual is positive, predicted is negative --> False Negative\n",
        "        training_results_df.loc[i, 'FN'] = 1    # Set FN to 1; leave other values at 0\n",
        "    elif actual_value == 2 and predicted_value == 4: # actual is negative, predicted is positive --> False Positive\n",
        "        training_results_df.loc[i, 'FP'] = 1    # Set FP to 1; leave other values at 0\n",
        "    elif actual_value == 2 and predicted_value == 2: # actual is negative, predicted is negative --> True Negative\n",
        "        training_results_df.loc[i, 'TN'] = 1    # Set TN to 1; leave other values at 0\n",
        "        \n",
        "\n",
        "# for each column of the above dataframe, take the sum\n",
        "num_tp = np.sum(training_results_df['TP'])\n",
        "num_tn = np.sum(training_results_df['TN'])\n",
        "num_fp = np.sum(training_results_df['FP'])\n",
        "num_fn = np.sum(training_results_df['FN'])\n",
        "\n",
        "\n",
        "# check: the sum of the above four numbers should be equal to \n",
        "#  the number of observations ( which is also the number of rows of this dataframe)\n",
        "print( num_tp + num_tn + num_fp + num_fn )\n",
        "print( training_results_df.shape[0])\n",
        "\n",
        "# STEP 3: Use the above numbers to compute the accuracy, precision, and recall \n",
        "# TODO: modify the codes below to do this on the test dataset (currently it's for the training dataset)\n",
        "\n",
        "accuracy = ( num_tp + num_tn ) / ( num_tp + num_tn + num_fp + num_fn )\n",
        "precision = ( num_tp ) / ( num_tp + num_fp )\n",
        "recall = ( num_tp  ) / ( num_tp + num_fn )\n",
        "\n",
        "print('Accuracy:')\n",
        "print(accuracy)\n",
        "print('Precision:')\n",
        "print(precision)\n",
        "print('Recall:')\n",
        "print(recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Def05GoLEFDr"
      },
      "source": [
        "***Exercise 2***\n",
        "\n",
        "We created a prediction function called `predict_cancer_class` above, whose codes we reproduced below\n",
        "```\n",
        "def predict_cancer_class( clump_thickness, predicted_class ):\n",
        "    if clump_thickness <= 6 :\n",
        "        if uniformity_cellsize <= 4:\n",
        "            predicted_class = 2\n",
        "        else:\n",
        "            predicted_class = 4\n",
        "    else:\n",
        "        predicted_class = 4\n",
        "        \n",
        "    return( predicted_class )\n",
        "```\n",
        "Recall that we came up with this function based on patterns we observed as we explore the training dataset.\n",
        "\n",
        "\n",
        "Please explore the training dataset to find other patterns that can be used to create a different prediction model or to modify the above function. Then, write the new function definition in the code cell below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULjMQxe3EFDr"
      },
      "outputs": [],
      "source": [
        "# explore the training data here\n",
        "# you can add additional/new code cells as necessary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQMZfMGwEFDr"
      },
      "outputs": [],
      "source": [
        "# explore the training data here\n",
        "# you can add additional/new code cells as necessary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jldCTx7ZEFDr"
      },
      "outputs": [],
      "source": [
        "# TODO: Write a new prediction function below \n",
        "\n",
        "def predict_cancer_class_newmodel(  .... ) :\n",
        "    # ...\n",
        "    # ...\n",
        "\n",
        "\n",
        "\n",
        "## Assess the performance of your new model\n",
        "\n",
        "# STEP 1: Use the predict_cancer_class() function to make a prediction on the test dataset\n",
        "\n",
        "y_train_predicted = np.zeros( y_train.shape ).astype(int)\n",
        "y_train_predicted = pd.Series(y_train_predicted)\n",
        "y_train_predicted.index = y_train.index\n",
        "\n",
        "# make a prediction for the value of class, for each row in the training dataset.\n",
        "for index in X_train.index :   \n",
        "    # MODIFY THE LINE BELOW TO USE YOUR NEW PREDICTION FUNCTION\n",
        "    y_train_predicted[index] = predict_cancer_class_newmodel( X_train['COLNAME1'][index] , X_train['COLNAME2'][index] )\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "## You do not have to modify the code cell below this line\n",
        "## --------------------------------\n",
        "# STEP 2: Take each predictions from STEP 1 and count the number of true positives, true negatives, etc.\n",
        "\n",
        "# first set up a placeholder dataframe\n",
        "training_results_df = pd.DataFrame( {'y_train': y_train, # this column contains the actual y values in the training data\n",
        "                                     'y_train_predicted': y_train_predicted, # this column contains the predicted y values\n",
        "                                     'TP': np.zeros( len(y_train) ), # fill this column with zeros for now \n",
        "                                     'TN': np.zeros( len(y_train) ), # fill this column with zeros for now\n",
        "                                     'FP': np.zeros( len(y_train) ), # fill this column with zeros for now\n",
        "                                     'FN': np.zeros( len(y_train) ) # fill this column with zeros for now \n",
        "                                    })\n",
        "\n",
        "\n",
        "# we will go through each row of the dataframe by looping over its row indices\n",
        "for i in training_results_df.index : \n",
        "    actual_value = training_results_df.loc[i, 'y_train']      # get value in row index i, column y_train\n",
        "    predicted_value = training_results_df.loc[i, 'y_train_predicted']  # get value in row index i, column y_train_predicted\n",
        "    \n",
        "    if actual_value == 4 and predicted_value == 4:   # actual is positive, predicted is positive --> True Positive\n",
        "        training_results_df.loc[i, 'TP'] = 1    # Set TP to 1; leave other values at 0\n",
        "    elif actual_value == 4 and predicted_value == 2: # actual is positive, predicted is negative --> False Negative\n",
        "        training_results_df.loc[i, 'FN'] = 1    # Set FN to 1; leave other values at 0\n",
        "    elif actual_value == 2 and predicted_value == 4: # actual is negative, predicted is positive --> False Positive\n",
        "        training_results_df.loc[i, 'FP'] = 1    # Set FP to 1; leave other values at 0\n",
        "    elif actual_value == 2 and predicted_value == 2: # actual is negative, predicted is negative --> True Negative\n",
        "        training_results_df.loc[i, 'TN'] = 1    # Set TN to 1; leave other values at 0\n",
        "        \n",
        "\n",
        "# for each column of the above dataframe, take the sum\n",
        "num_tp = np.sum(training_results_df['TP'])\n",
        "num_tn = np.sum(training_results_df['TN'])\n",
        "num_fp = np.sum(training_results_df['FP'])\n",
        "num_fn = np.sum(training_results_df['FN'])\n",
        "\n",
        "\n",
        "# check: the sum of the above four numbers should be equal to \n",
        "#  the number of observations ( which is also the number of rows of this dataframe)\n",
        "print( num_tp + num_tn + num_fp + num_fn )\n",
        "print( training_results_df.shape[0])\n",
        "\n",
        "# STEP 3: Use the above numbers to compute the accuracy, precision, and recall \n",
        "\n",
        "accuracy = ( num_tp + num_tn ) / ( num_tp + num_tn + num_fp + num_fn )\n",
        "precision = ( num_tp ) / ( num_tp + num_fp )\n",
        "recall = ( num_tp  ) / ( num_tp + num_fn )\n",
        "\n",
        "print('Accuracy:')\n",
        "print(accuracy)\n",
        "print('Precision:')\n",
        "print(precision)\n",
        "print('Recall:')\n",
        "print(recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3T6QEHBEFDs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ty5VM-2EFDs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}